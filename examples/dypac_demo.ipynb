{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dypac import Dypac\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from nilearn import datasets\n",
    "from nilearn import image\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.interfaces.fmriprep import load_confounds\n",
    "from nilearn import plotting\n",
    "from nilearn.decomposition import DictLearning, CanICA\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading a yem subjects from the developmental movie watching dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = 6\n",
    "dev_dataset = datasets.fetch_development_fmri(n_subjects=n_subjects)\n",
    "epi_filename = dev_dataset.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf, _ = load_confounds(epi_filename, strategy=[\"motion\"], motion=\"basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run dypac. First we specify the model, with the main relevant options. Then we fit the model on the developmental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultiNiftiMasker.fit] Loading data from [/home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz,\n",
      " /home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz,\n",
      " /home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz,\n",
      " /home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz,\n",
      " /home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar004_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz,\n",
      " /home/haoting/nilearn_data/development_fmri/development_fmri/sub-pixar005_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz]\n",
      "[MultiNiftiMasker.fit] Computing mask\n"
     ]
    }
   ],
   "source": [
    "model = Dypac(n_clusters=50, n_states=150, verbose=1, n_init=1, n_init_aggregation=1, n_replications=20, \n",
    "              detrend=True, smoothing_fwhm=5, standardize=True, n_batch=2, threshold_sim=0)\n",
    "model.fit(epi_filename, confounds=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize components maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 7# the component number\n",
    "comp = model.masker_.inverse_transform(model.components_[num_comp,:].todense())\n",
    "plotting.view_img(comp, threshold=0.1, vmax=1, title=\"Dwell time: {dt}\".format(dt=model.dwell_time_[num_comp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can project the data of one subject in the parcellation space, and visualize the time course of a parcel. Note that we shift the component index, because the first coefficient of the parcellation space corresponds to the intercept, which is not included in `components_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_s = 0 # the subject number\n",
    "weights = model.transform(epi_filename[num_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weights[:, num_comp + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize one volume of the 4D data (after preprocessing is applied):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_t = 65 # the frame number\n",
    "img = model.load_img(epi_filename[num_s])\n",
    "plotting.view_img(image.index_img(img, [num_t]), vmax=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compress the data in the parcellation space, to look if the approximation is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_r = model.compress(img)\n",
    "plotting.view_img(image.index_img(img_r, [num_t]), vmax=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to generate a R2 map, which quantifies the quality of this embedding. It computes the fraction of the variance of fMRI time series captured by the parcels. A score of 1 means perfect approximation. The score can be negative, in which case the parcellation approximation performs worst than the average of the signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(img, conf[0])\n",
    "plotting.view_img(score, vmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
